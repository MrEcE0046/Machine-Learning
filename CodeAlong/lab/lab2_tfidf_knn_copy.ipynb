{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "tags = pd.read_csv(\"Tags.csv\")\n",
    "movies = pd.read_csv(\"movies.csv\")\n",
    "ratings = pd.read_csv(\"ratings.csv\")\n",
    "links = pd.read_csv(\"links.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Behåll\n",
    "movies[\"genres\"] = movies[\"genres\"].str.replace(\"|\", \" \", regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Behåll\n",
    "tags = tags[tags['tag'].apply(lambda x: isinstance(x, str))]\n",
    "merged_tags = tags.groupby(\"movieId\")[\"tag\"].apply(lambda x: \" \".join(set(x))).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Behåll\n",
    "\n",
    "filtered_movies = pd.merge(movies, merged_tags, on=\"movieId\", how=\"inner\")\n",
    "filtered_movies = pd.merge(filtered_movies, links, on=\"movieId\", how=\"inner\")\n",
    "filtered_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import re\n",
    "import unicodedata\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    tags = pd.read_csv(\"Tags.csv\")\n",
    "    movies = pd.read_csv(\"movies.csv\")\n",
    "    ratings = pd.read_csv(\"ratings.csv\")\n",
    "    links = pd.read_csv(\"links.csv\")\n",
    "\n",
    "    return tags, movies, ratings, links\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Behåll\n",
    "\n",
    "def clean_text(text):\n",
    "    if type(text)==str:\n",
    "        text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode() \n",
    "        # converts to lowercase\n",
    "        text = text.lower()\n",
    "    \n",
    "        # removes special characters, numbers, and punctuation\n",
    "        text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prep(tags, movies, links):\n",
    "    movies[\"genres\"] = movies[\"genres\"].str.replace(\"|\", \" \", regex=False)\n",
    "    tags = tags[tags['tag'].apply(lambda x: isinstance(x, str))]\n",
    "    merged_tags = tags.groupby(\"movieId\")[\"tag\"].apply(lambda x: \" \".join(set(x))).reset_index()\n",
    "    filtered_movies = pd.merge(movies, merged_tags, on=\"movieId\", how=\"inner\")\n",
    "    filtered_movies = pd.merge(filtered_movies, links, on=\"movieId\", how=\"inner\")\n",
    "\n",
    "    text_columns = filtered_movies.columns[filtered_movies.dtypes == 'object']\n",
    "    for col in text_columns:\n",
    "        filtered_movies[col] = filtered_movies[col].apply(clean_text)\n",
    "    \n",
    "    return filtered_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf(filtered_movies):\n",
    "    text_data1 = filtered_movies[\"genres\"].tolist()\n",
    "    vectorizer1 = TfidfVectorizer()\n",
    "    tfidf_matrix1 = vectorizer1.fit_transform(text_data1)\n",
    "\n",
    "    text_data2 = filtered_movies[\"tag\"].tolist()\n",
    "    vectorizer2 = TfidfVectorizer()\n",
    "    tfidf_matrix2 = vectorizer2.fit_transform(text_data2) # ändarade vectorizer1 till 2\n",
    "\n",
    "    combined_matrix = hstack((tfidf_matrix1, tfidf_matrix2))\n",
    "\n",
    "    model_knn = NearestNeighbors(metric = \"cosine\", algorithm = \"auto\")\n",
    "    model_knn.fit(combined_matrix)\n",
    "\n",
    "    return model_knn, combined_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rating_features(ratings, movies):\n",
    "    x = ratings[\"userId\"].value_counts() > 200\n",
    "    y = x[x].index\n",
    "    ratings = ratings[ratings[\"userId\"].isin(y)]\n",
    "    ratings_with_movies = ratings.merge(movies, on= \"movieId\")\n",
    "\n",
    "    num_rating = ratings_with_movies.groupby(\"title\")[\"rating\"].count().reset_index()\n",
    "\n",
    "    num_rating.rename(columns={\"rating\": \"num_of_rating\"}, inplace=True)\n",
    "    final_rating = ratings_with_movies.merge(num_rating, on=\"title\") # sätter ihop dataset som både har title kolumner på title\n",
    "    final_rating = final_rating.drop(columns=[\"title\", \"genres\"])\n",
    "\n",
    "    return final_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(movie_name, combined_matrix, model_knn, filtered_movies, top_n = 5):\n",
    "\n",
    "    movie_id = filtered_movies[filtered_movies[\"title\"] == movie_name].index[0]\n",
    "\n",
    "    # Get the row corresponding to the movie of interest\n",
    "    movie = combined_matrix[movie_id, :]\n",
    "    \n",
    "    # Get the indices and distances of the nearest neighbors\n",
    "    distances, indices = model_knn.kneighbors(movie.reshape(1, -1), n_neighbors= top_n+1)\n",
    "    \n",
    "    # Return the movie titles corresponding to the nearest neighbors\n",
    "    return filtered_movies[[\"movieId\",\"title\", \"genres\", \"tmdbId\"]].iloc[indices[0][0:top_n+1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sparse(list, final_rating):\n",
    "    top50_n_ratings = pd.merge(list, final_rating, on=\"movieId\", how=\"inner\")\n",
    "\n",
    "    movie_pivot = top50_n_ratings.pivot_table(columns=\"userId\", index=\"title\", values=\"rating\")\n",
    "    movie_pivot.fillna(0, inplace=True)\n",
    "\n",
    "    movie_sparse = csr_matrix(movie_pivot)\n",
    "\n",
    "    return movie_pivot, movie_sparse, top50_n_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(movie_sparse, movie_pivot):\n",
    "    model = NearestNeighbors(metric=\"cosine\", algorithm=\"brute\")\n",
    "    model.fit(movie_sparse)\n",
    "\n",
    "    movie_names = movie_pivot.index.tolist() # Gjorde till en lista för streamlit\n",
    "\n",
    "    return movie_names, model\n",
    "\n",
    "# movie_names, model = make_model(movie_sparse, movie_pivot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(movie_name, movie_pivot, model, top50_n_ratings):\n",
    "    movie_list = []\n",
    "\n",
    "    movie_id = np.where(movie_pivot.index == movie_name)[0][0]\n",
    "    distance, suggestion = model.kneighbors(movie_pivot.iloc[movie_id,:].values.reshape(1,-1), n_neighbors=6) \n",
    "    \n",
    "    # poster_url = get_poster(suggestion, book_pivot, final_rating)\n",
    "    \n",
    "    for i in range(len(suggestion)):\n",
    "        movies = movie_pivot.index[suggestion[i]]\n",
    "        for j in movies:\n",
    "            movie_list.append(j)\n",
    "    \n",
    "    return movie_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_list[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    tags, movies, ratings, links = load_data()\n",
    "    filtered_movies = data_prep(tags, movies, links)\n",
    "    model_knn, combined_matrix = tfidf(filtered_movies)\n",
    "    final_rating = rating_features(ratings, movies)\n",
    "\n",
    "    return combined_matrix, model_knn, final_rating, filtered_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "   combined_matrix, model_knn, final_rating, filtered_movies = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['goldeneye 1995',\n",
       " 'tomorrow never dies 1997',\n",
       " 'rock the 1996',\n",
       " 'world is not enough the 1999',\n",
       " 'die hard 2 1990',\n",
       " 'hunt for red october the 1990']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def choose_title(combined_matrix, model_knn, final_rating, filtered_movies):\n",
    "\n",
    "    movie_name = \"goldeneye 1995\"\n",
    "\n",
    "    list = get_recommendations(movie_name, combined_matrix, model_knn, filtered_movies, top_n = 50) # movie_id är filmen som man väljer\n",
    "    movie_pivot, movie_sparse, top50_n_ratings = make_sparse(list, final_rating)\n",
    "    movie_names, model = make_model(movie_sparse, movie_pivot)\n",
    "    x = recommend(movie_name, movie_pivot, model, top50_n_ratings)\n",
    "    \n",
    "    return print(x)\n",
    "\n",
    "x = choose_title(combined_matrix, model_knn, final_rating, filtered_movies)\n",
    "x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Behåll\n",
    "\n",
    "# text_columns = filtered_movies.columns[filtered_movies.dtypes == 'object']\n",
    "# for col in text_columns:\n",
    "#     filtered_movies[col] = filtered_movies[col].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(book_names, book_pivot, model, top50_n_ratings):\n",
    "    book_list = []\n",
    "\n",
    "    book_id = np.where(book_pivot.index == book_names)[0][0]\n",
    "    distance, suggestion = model.kneighbors(book_pivot.iloc[book_id,:].values.reshape(1,-1), n_neighbors=6) \n",
    "    \n",
    "    # poster_url = get_poster(suggestion, book_pivot, final_rating)\n",
    "    \n",
    "    for i in range(len(suggestion)):\n",
    "        books = book_pivot.index[suggestion[i]]\n",
    "        for j in books:\n",
    "            book_list.append(j)\n",
    "    \n",
    "    return book_list\n",
    "#, poster_url\n",
    "movie_name = \"heat 1995\"\n",
    "movie_list = recommend(movie_name, movie_pivot, model, top50_n_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filtered_movies' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mfiltered_movies\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'filtered_movies' is not defined"
     ]
    }
   ],
   "source": [
    "filtered_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Används inte\n",
    "\n",
    "# tfidf_movies = filtered_movies.copy()\n",
    "# tfidf_movies[\"tfidf\"] = filtered_movies[\"genres\"] + \" \" + filtered_movies[\"tag\"]\n",
    "# tfidf_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Behåll\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "text_data1 = filtered_movies[\"genres\"].tolist()\n",
    "vectorizer1 = TfidfVectorizer()\n",
    "tfidf_matrix1 = vectorizer1.fit_transform(text_data1)\n",
    "\n",
    "text_data2 = filtered_movies[\"tag\"].tolist()\n",
    "vectorizer2 = TfidfVectorizer()\n",
    "tfidf_matrix2 = vectorizer1.fit_transform(text_data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Behåll\n",
    "\n",
    "from scipy.sparse import hstack\n",
    "combined_matrix = hstack((tfidf_matrix1, tfidf_matrix2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Behåll\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "model_knn = NearestNeighbors(metric = \"cosine\", algorithm = \"auto\")\n",
    "model_knn.fit(combined_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#================================================================================================\n",
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "x = ratings[\"userId\"].value_counts() > 200\n",
    "y = x[x].index\n",
    "ratings = ratings[ratings[\"userId\"].isin(y)]\n",
    "ratings_with_movies = ratings.merge(movies, on= \"movieId\")\n",
    "\n",
    "num_rating = ratings_with_movies.groupby(\"title\")[\"rating\"].count().reset_index()\n",
    "\n",
    "num_rating.rename(columns={\"rating\": \"num_of_rating\"}, inplace=True)\n",
    "final_rating = ratings_with_movies.merge(num_rating, on=\"title\") # sätter ihop dataset som både har title kolumner på title\n",
    "final_rating\n",
    "\n",
    "# final_rating = final_rating[final_rating[\"num_of_rating\"]>50] # tar bort alla böcker med mindre än 50 ratings\n",
    "# final_rating.drop_duplicates([\"userId\", \"title\"], inplace=True) # tar bort alla dubletter\n",
    "\"\"\"\n",
    "Av de 50 som jag får ut av tfidf kan man kanske lägga in titlarna med final rating och sen köra pivot tabell och \n",
    "sen en nearestneighbor till på de titlarna.\n",
    "\"\"\"\n",
    "# movie_pivot = final_rating.pivot_table(columns=\"userId\", index=\"title\", values=\"rating\")\n",
    "# movie_pivot.fillna(0, inplace=True)\n",
    "\n",
    "# movie_sparse = csr_matrix(movie_pivot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Funkar bäst hittils -= TF-IDF =- \"\"\"\n",
    "# Behåll\n",
    "\n",
    "def get_recommendations(movie_id, combined_matrix, model_knn, top_n = 5):\n",
    "    # Get the row corresponding to the movie of interest\n",
    "    movie = combined_matrix[movie_id, :]\n",
    "    \n",
    "    # Get the indices and distances of the nearest neighbors\n",
    "    distances, indices = model_knn.kneighbors(movie.reshape(1, -1), n_neighbors= top_n+1)\n",
    "    \n",
    "    # Return the movie titles corresponding to the nearest neighbors\n",
    "    return filtered_movies[[\"movieId\",\"title\", \"genres\", \"tmdbId\"]].iloc[indices[0][0:top_n+1]]\n",
    "\n",
    "movie_name = \"heat 1995\"\n",
    "movie_id = filtered_movies[filtered_movies[\"title\"] == movie_name].index[0]\n",
    "\n",
    "\n",
    "print(\"Recommendations for movie:\", filtered_movies[\"title\"].iloc[movie_id])\n",
    "list = get_recommendations(movie_id, combined_matrix, model_knn, top_n=50)\n",
    "list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list\n",
    "# top50_n_ratings = pd.merge(list, ratings, on=\"movieId\", how=\"inner\")\n",
    "# top50_n_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" jag skulle kunna nöja mig med ett resultat från de 50 som har flest ratings och med högst medelvärde. \n",
    "Men jag forskar vidare om det blir ett bättre resultat med någon model med ratings. \n",
    "\"\"\"\n",
    "# top_mean = top50_n_ratings.groupby([\"movieId\",\"title\", \"tmdbId\"])[\"rating\"].agg([\"count\", \"mean\"]).reset_index()\n",
    "# sorted_mean = top_mean.nlargest(5, \"mean\")\n",
    "# sorted_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_rating = final_rating.drop(columns=[\"title\", \"genres\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Jag forskar på om man kan med tf idf få fram de 50 mest relavanta filmerna och sen med rating få fram \n",
    "de 5 med mest relavant rating. \"\"\"\n",
    "\n",
    "top50_n_ratings = pd.merge(list, final_rating, on=\"movieId\", how=\"inner\")\n",
    "\n",
    "movie_pivot = top50_n_ratings.pivot_table(columns=\"userId\", index=\"title\", values=\"rating\")\n",
    "movie_pivot.fillna(0, inplace=True)\n",
    "\n",
    "movie_sparse = csr_matrix(movie_pivot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top50_n_ratings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(movie_sparse, movie_pivot):\n",
    "    model = NearestNeighbors(metric=\"cosine\", algorithm=\"brute\")\n",
    "    model.fit(movie_sparse)\n",
    "\n",
    "    movie_names = movie_pivot.index.tolist() # Gjorde till en lista för streamlit\n",
    "\n",
    "    return movie_names, model\n",
    "\n",
    "movie_names, model = make_model(movie_sparse, movie_pivot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def recommend(movie_name, movie_pivot, model, top50_n_ratings):\n",
    "    movie_list = []\n",
    "\n",
    "    book_id = np.where(movie_pivot.index == movie_names)[0][0]\n",
    "    distance, suggestion = model.kneighbors(movie_pivot.iloc[book_id,:].values.reshape(1,-1), n_neighbors=6) \n",
    "    \n",
    "    # poster_url = get_poster(suggestion, book_pivot, final_rating)\n",
    "    \n",
    "    for i in range(len(suggestion)):\n",
    "        movies = movie_pivot.index[suggestion[i]]\n",
    "        for j in movies:\n",
    "            movie_list.append(j)\n",
    "    \n",
    "    return movie_list\n",
    "#, poster_url\n",
    "movie_name = \"heat 1995\"\n",
    "movie_list = recommend(movie_name, movie_pivot, model, top50_n_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" slutlig lista på de fem efter TF IDF och kneighbors, oklart hur lång tid uträkningen tar... \n",
    "kanske kneighbors inte är den mest optimala här.. \"\"\"\n",
    "\n",
    "movie_list[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" =============================================================================================\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "combined_matrix\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "model = vectorizer.fit_transform(tfidf_movies[\"tfidf\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# def search(title):\n",
    "title = \"toy story 1995\"\n",
    "query_vector = vectorizer.transform([title])\n",
    "similarity = cosine_similarity(query_vector, model).flatten()\n",
    "indices = np.argpartition(similarity, -50)[-50:]\n",
    "result = filtered_movies.iloc[indices][[\"title\", \"genres\"]].values\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "movie_input = widgets.Text(\n",
    "    value= \"toy story 1995\",\n",
    "    description = \"Movie:\",\n",
    "    disabled = False\n",
    ")\n",
    "movie_list = widgets.Output()\n",
    "\n",
    "def on_type(data):\n",
    "    with movie_list:\n",
    "        movie_list.clear_output()\n",
    "        title = data[\"new\"]\n",
    "        if len(title) > 3:\n",
    "            display(search(title))\n",
    "\n",
    "movie_input.observe(on_type, names=\"value\")\n",
    "\n",
    "display(movie_input, movie_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
